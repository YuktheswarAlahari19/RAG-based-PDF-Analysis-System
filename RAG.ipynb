{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install --upgrade astrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install -q cassandra-driver\n",
    "%pip install -q langchain\n",
    "%pip install -q chat-deepseek-api\n",
    "%pip install -q pypdf\n",
    "%pip install -q cassio>=0.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.auth import PlainTextAuthProvider\n",
    "import json\n",
    "\n",
    "cloud_config= {'secure_connect_bundle':'secure-connect-pdf-qa (1).zip'}\n",
    "\n",
    "with open(\"D:\\PROJECTS\\RagProject\\yukkualahari@gmail.com-token (1).json\") as f:\n",
    "    secrets = json.load(f)\n",
    "    \n",
    "CLIENT_ID=secrets['clientId']\n",
    "CLIENT_SECRET=secrets['secret']\n",
    "\n",
    "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.11-7cde36df13c4\n"
     ]
    }
   ],
   "source": [
    "row = session.execute(\"select release_version from system.local\").one()\n",
    "\n",
    "if row:\n",
    "    print(row[0])\n",
    "else:\n",
    "    print(\"An error occurred.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install langchain-deepseek-official langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install openrouter-python langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukku\\AppData\\Local\\Temp\\ipykernel_9700\\392549622.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    temperature=0.3,\n",
    "    num_gpu=1,  # Use GPU acceleration\n",
    "    num_predict=128,\n",
    "    num_ctx=800  # Use 1024 context tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukku\\AppData\\Local\\Temp\\ipykernel_9700\\2996441843.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "d:\\PROJECTS\\RagProject\\Rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"D:\\PROJECTS\\RagProject\\how-to-win-friends-and-influence-people.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyspace = \"pdf_qa_name\"  \n",
    "table_name = \"pdf_qa_table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Cassandra(\n",
    "    embedding=embeddings,\n",
    "    session=session,\n",
    "    keyspace=keyspace,\n",
    "    table_name=table_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_documents(pages)\n",
    "vectorstore.add_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_query = f\"SELECT * FROM {keyspace}.{table_name}\"\n",
    "rows = session.execute(default_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(rows):\n",
    "    print(f\"\\nRow [{idx}]\")\n",
    "    print(f\"row_id: {row.row_id}\")\n",
    "    print(f\"embedding_vector: {str(row.vector)[:64]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,  # Only this line changes from previous OpenAI setup\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your PDFs] → [Cassandra Vector Store (unchanged)] \n",
    "                     ↓\n",
    "[Local DeepSeek LLM] → [Conversational Chain (modified)]\n",
    "                     ↑\n",
    "           [Docker Container (ollama:11434)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you analyze the document and explain what is the big secret of dealing with people?\"\n",
    "result = qa_chain({\"question\": query, \"chat_history\": chat_history})\n",
    "chat_history.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In order to get the most out of this book, devote a deep, driving desire to mastering the principles of human relations. By keeping a record of specific examples of how to apply these principles in practice, you will be inspired and motivated to make greater efforts in future endeavors. Additionally, by developing a strong desire to learn and improve your skills, you will be able to more effectively communicate with others and achieve better results in all areas of life.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
